
# Java并发机制的底层实现
Java多线程并发编程两个关键字:synchronized和volatile.
## volatile
volatile是轻量级的synchronized,执行成本更低,因为它不会引起线程上下文的切换和调度.它在多处理器开发中保证了共享变量的"可见性".  
如果一个字段被声明为volatile那么java内存模型确保所有线程看到这个变量的值是一致的.
```java
  instance = new Singleton();  //instance 是volatile变量
```
转成汇编代码发现多了lock指令,lock指令在多核处理器下会引发两件事情:
>* 将当前处理器缓存行的数据写回到系统内存
>* 这个写回内存的操作会使其他CPU里缓存了该内存地址的数据无效

**如何实现**:多处理器下为了保证各个处理器的缓存是一致的,就会实现缓存一致性协议: 每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了.
当处理器发现自己缓存行所对应的内存地址被修改就会将当前处理器的缓存行设置为无效状态,当处理器对这个数据进行修改时就会从系统内存重新读取到处理器缓存中(强行执行缓存行填充).
LOCK#信号一般不锁总线,而是锁缓存.如果访问的内存区域已经缓存在处理器内部,那么就会锁定这块内存区域的缓存并回写到内存,并使用缓存一致性来
确保修改的原子性.
#### volatile的使用优化
追加字节至字节:多数处理器的高速缓存行是64字宽,不支持部分填充缓存行[不足64字节,多组数据放在同一个缓存行中,考虑到缓存一致性机制其他处理器不能访问自己高速缓存中的其他数据]
如果共享变量不会被频繁写,不应该采用追加字节方式.    

**CPU术语**:内存屏障 缓存行|缓冲行 缓存行填充 缓存命中 写命中  

## synchronized的实现原理  
**Java基础**: Java中每个对象都可以视为锁
 > * 普通同步方法,锁是当前实例对象
 > * 静态同步方法,锁是当前类的Class对象
 > * 同步方法块,锁是Synchronized括号中配置的对象  

JVM使用Monitor对象来实现方法同步和代码块同步.
### Java对象头
synchronized使用的锁是放在Java对象头中的.
Java对象头包括三(2)个部分:Mark Word, Class Metadata Address, Array lengh,非数组类型的对象没有Array length,每个部分为一个字宽.
Markword中包括25bit的hashcode,4bit的对象分代年龄,以及锁信息(锁状态 是否偏向锁 锁标志位),这里具体数值按照32位处理器. 

### 锁的升级
#### 偏向锁  
当一个线程访问同步代码并获得锁时,会在对象头和栈帧中的锁记录里存储锁偏向的线程ID,以后该线程在进入和退出同步块时不需要进行CAS操作来
加锁和释放锁,只需要测试一下对象头的Mark Word里是否存储着当前线程的偏向锁(偏向锁的mark word里会有一个线程ID的字段,不存hashcode).  
**偏向锁撤销**(设计到栈的锁记录和对象头的mark word)
偏向锁只有在其他线程竞争偏向锁时,持有偏向锁的线程才会释放锁(需等待全局安全点--这个时间点上没有正在执行的字节码).

#### 轻量级锁 
> * 加锁: 线程在执行同步快之前,JVM会先在当前线程的栈帧中创建用于存储锁记录的空间并将对象头中的Mark Word复制到锁记录中(Displaced Mark Word).
然后线程尝试使用CAS将对象头中的Mark Word替换位指向锁记录的指针.如果成功,当前线程获得锁,如果失败,其他线程竞争锁, 当前线程进入自旋状态.
> * 撤销: 使用原子的CAS将Displaced Mark Word 替换回到对象头,失败表示锁存在竞争,锁就会膨胀为重量级锁.

思考: 为什么不能锁降级?[提示: 重量级锁不使用自旋,不会消耗CPU,但响应时间慢]

## 原子操作的实现原理  
原子操作: 不可中断的一个或一系列操作  
### 处理器如何实现原子操作  
处理器保证从系统内存中读取或写入一个字节是原子的(限制了其他处理器),但是对于复杂的内存处理(跨总线宽度 跨多个缓存行 跨页表的访问)不能自动保证
原子性.有两种机制保证复杂内存操作的原子性:
> * 总线锁  总线上输出LOCK#信号,将其他处理器的请求阻塞,使得该处理器独享内存
> * 缓存锁  总线锁将CPU和整个内存之间的通信隔断了,低效.  

ps:当操作的数据不能被缓存在处理器内部或者操作的数据跨多个缓存行时,应该调用总线锁定,有些处理器也不支持缓存锁定,但提供了一些指令来实现.  

### Java如何实现原子操作(两种方式)
### 循环CAS 
Java的CAS操作使用的是处理器提供的CMPXCHG指令实现.思考:自旋CAS   
CAS实现原子操作的三大问题:
> * ABA问题  解决思路: 给变量添加版本号
> * 自旋CAS开销大
> * 只能保证一个共享变量的原子操作  解决: 锁  多个共享变量合成为一个共享变量(AtomicReference).  

### 锁 
只有获得锁的线程才能操作锁定的内存区域,JVM的锁机制是基于循环CAS实现的(参考轻量级锁).  

**CPU术语**: CAS 

# Java 内存模型
## 基础 
两个问题: 线程之间如何通信以及线程之间如何同步
线程之间的通信机制(并发模型):
> * 共享内存: 线程共享程序的公共状态,通过写-读内存中的公共状态进行隐式通信
> * 消息传递: 线程间必须通过发送消息来显式进行通信

同步: 用于控制不同线程间操作发生相对顺序的机制 

JMM定义了线程和主内存之间的抽象关系: 线程之间的共享变量存储在主内存中,每个内存都有一个私有的本地内存,其中存储了该线程读写共享变量的副本.本地内存
是一个抽象概念,并不真实存在,它涵盖了缓存,写缓冲区,寄存器以及其他的硬件和编译器优化.

**共享变量在线程间的传递**:  Thread A -- 主内存 -- Thread B  

### 重排序(为了提高执行程序的性能)
> * 编译器优化的重排序 编译器在不改变单线程程序语义的前提下,调整语句的执行顺序
> * 指令级并行的重排序(ILP)  如果不存在数据依赖性,处理器可以调整语句对应机器指令的执行顺序
> * 内存系统的重排序 处理器使用了缓存和读写缓冲区导致加载和存储操作看起来像是在乱序执行

JMM通过禁止编译器重排序和插入特定类型的内存屏障为程序员提供一致的内存可见性保证.

**写缓冲区**: 
写缓冲区临时保存向内存写入的数据,好处:
> * 保证指令流水线持续运行,避免了处理器停下来等待向内存写入数据而产生的延迟
> * 采用批处理方式刷新写缓冲区,合并写缓冲区内对一个内存地址的多次写入,减少了对内存总线的占用  

问题在于写缓冲区仅对所在处理器可见,所以在多处理器环境下内存可见性得不到一致性的保证.  
四种重排序规则和四种相对应的内存屏障,重点:**StoreLoad Barriers**.

### happens-before 

JSR-133使用happens-before来阐述操作之间的内存可见性.   
有很多规则,其中一条:对一个volatile域的写,happens-before于对任意后续对这个volatile域的读.  
happens-before仅仅要求前一个操作对后一个操作可见且前一个操作按顺序排在后一个操作之前.并不意味着前一个操作在后一个操作之前执行.     
 
 \
**关系图**:  
    程序员 -- happens-before -- JMM(重排序相关)

**数据依赖性**: 如果两个操作访问共同一个变量,其中一个为写操作,那么这两个操作之间存在数据依赖性,重排序后执行结果会变化.编译器和处理器在重排序的时候会考虑
数据依赖性(这里指的是单个处理器中执行的指令序列和单线程中执行的操作)

**as-if-serial**  
不管如何重排序,单线程程序的执行结果不会发生改变.这是编译器,runtime,处理器都必须遵守的语义.因此,编译器和处理器都不会对存在数据依赖性的操作做重排序.  

**控制依赖性  猜测执行将计算结果保存到重排序缓存里**

## 顺序一致性  
### 顺序一致性模型
### 未同步程序在JMM中执行情况
> * JMM不保证单线程内的操作会按照程序的顺序执行
> * JMM不保证所有线程能看到一致的操作执行顺序
> * JMM不保证对64位的long和double型变量的写操作具有原子性(涉及到总线事务的概念 任意时间点最多只能有一个处理器可以访问内存,确保了单个总线事务之中的
内存读写操作具有原子性,所以在32位处理器上可能被拆分位两个32位的写操作,被分配到不同的事务总线中执行,JSR-133开始,只允许拆为写操作,读操作必须具有原子性)









